---

<aside>
ğŸ’¡ MNIST Dataset
</aside>

<br>
</br>
<img width="727" alt="image" src="https://github.com/Dororo99/nvidia_dli/assets/136609617/ba84a117-66fe-4fe4-a878-10c376c00bd1">


- Training and Validation Data and Labels
    - x_train: í•™ìŠµì„ ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ì´ë¯¸ì§€
    - y_train: x_train ë°ì´í„°ì— ëŒ€í•œ ì •ë‹µ ë˜ëŠ” ê¸°ëŒ€ ì¶œë ¥ ê°’
    - x_valid: í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€
    - y_valid: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì •ë‹µ ë˜ëŠ” ê¸°ëŒ€ ì¶œë ¥ ê°’
- Loading the Data into Memory
    - Kerasë¥¼ ì‚¬ìš©
        
        ```python
        #import mnist by Keras
        from tensorflw.keras.datasets import mnist
        
        # the data, split between train and validation sets
        (x_train, y_train), (x_valid, y_valid) = mnist.load_data()
        
        #70000ê°œì˜ 28x28 ë°ì´í„° ì¤‘ 60000ê°œë¥¼ training ë‚˜ë¨¸ì§€ë¥¼ test
        x_train.shape
        x_valid.shape
        
        #pixelì´ë¯€ë¡œ [0,255]ì˜ ê°’ì„ ê°€ì ¸ì•¼ í•¨
        x_train.dtype
        x_train.min()
        x_train.max()
        x_train[0] #ì²«ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ arrayë¡œ ë‚˜íƒ€ë‚¸ê±°
        ```
        
        ```python
        array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,
                 18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,
                253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,
                253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,
                253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,
                205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,
                 90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,
                190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,
                253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,
                241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,
                148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,
                253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,
                253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,
                195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,
                 11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0],
               [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                  0,   0]], dtype=uint8)
        ```
        
    - matplotlib ì‚¬ìš©
        
        ```python
        import matplotlib.pyplot as plt
        
        #ìœ„ì˜ ì²«ë²ˆì§¸ ì´ë¯¸ì§€ë¥¼ grayscale imageë¡œ ë‚˜íƒ€ë‚¸ê±°
        image = x_train[0]
        plt.imshow(image, cmap='gray') 
        ```
        
- Flattening the Image Data
    - reshape ì‚¬ìš©
        
        ```python
        #28x28=784
        x_train = x_train.reshape(60000,784)
        x_valid = x_valid.reshape(10000,784)
        
        x_train.shape
        x_train[0]
        ```
        
        ```python
        array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,
               126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,
               253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,
               253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,
               253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,
               241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,
               253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,
               183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,
               229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,
               221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,
               213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,
               219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,
               226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
               136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
                 0,   0,   0,   0], dtype=uint8)
        
        #ìœ„ì™€ ë‹¤ë¥´ê²Œ ì´ë ‡ê²Œ í•˜ë©´ í•˜ë‚˜ì˜ array ì•ˆì—ì„œ í‘œí˜„ë¨ì„ ë³¼ ìˆ˜ ìˆìŒ
        ```
        
- Normalizing the Image Data
    - deep learning ëª¨ë¸ì´ float [0,1]ì—ì„œ ë” ì˜ ë‹¤ë¤„ì§€ê¸° ë•Œë¬¸ì— ì´ ë²”ìœ„ ë‚´ë¡œ ë„£ëŠ” ê²ƒì„ normalizationì´ë¼ê³  í•œë‹¤.
        - Converting integer values to floating point values between 0 and 1 is called normalization
        
        ```python
        x_train = x_train / 255
        x_valid = x_valid / 255
        
        #ê²°ê³¼ë¬¼ì„ ë³´ì
        x_train.dtype
        x_train.min()
        x_train.max()
        ```
        
- Categorically Encoding the Labels
    - Kerasë¥¼ ì´ìš©í•˜ì
        
        ```python
        import tensorflow.keras as keras
        num_categories = 10
        
        y_train = keras.utils.to_categorical(y_train, num_categories)
        y_valid = keras.utils.to_categorical(y_valid, num_categories)
        
        y_train[0:9]
        ```
        
        ```python
        array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
               [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
               [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
               [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
               [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],
               [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
               [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
               [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
               [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)
        ```
        
- Creating the Model
    - Instantiating the Model
        
        ```python
        from tensorflow.keras.models import Sequential
        
        model = Sequential()
        ```
        
    - Creating the Input Layer
        
        ```python
        from tensorflow.keras.layers. import Dense
        
        #512ê°œì˜ ë‰´ëŸ°ì„ ê°€ì§„ í•˜ë‚˜ì˜ hidden layer ì‚¬ìš©, reLu function ì‚¬ìš©,
        model.add(Dense(units=512, activation='relu', input_shape(784,)))
        ```
        
    - Creating the Hidden Layer
        
        ```python
        model.add(Dense(units = 512, activation='relu'))
        ```
        
    - Creating the Ouput Layer
        
        ```python
        # softmax: ê²°ê³¼ê°’ì´ [0,1]ì´ ë˜ë„ë¡ í•˜ëŠ”ë° ë§Œì•½ ì¹´í…Œê³ ë¦¬ê°€ 10ê°œë¼ë©´ [1,10]
        # í˜„ì¬ ì†ê¸€ì”¨ëŠ” 0ë¶€í„° 9ê¹Œì§€ ì¦‰, 10ê°œì˜ ì¶œë ¥ ì¹´í…Œê³ ë¦¬ê°€ ìˆë‹¤. ë”°ë¼ì„œ softmax í•¨ìˆ˜ë¥¼ í†µê³¼í•œ ê²°ê³¼ëŠ” ê° í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ë¡œ í•´ì„ëœë‹¤.
        model.add(Dense(units = num_classes, activation='softmax'))
        ```
        
    - Mode Summary
        
        ```python
        model.summary()
        ```
        
        <img width="695" alt="image" src="https://github.com/Dororo99/nvidia_dli/assets/136609617/77729aa4-428e-4345-9362-51b3fbe49ad5">

        
- Compiling the Model
    - loss functionì— ì–´ë–¤ê²ƒì„ ì‚¬ìš©í–ˆëŠ”ì§€ ì•Œë ¤ì£¼ê³  ì–¼ë§ˆë‚˜ ì˜ í•™ìŠµë˜ëŠ”ì§€ íŒë‹¨ í•  ìˆ˜ ìˆìŒ
        
        ```python
        model.compile(loss='categorical_crossentropy', metrics=['accuracy']
        ```
        
    - Training the Model
        
        ```python
        #By using model's fit method
        history  = model.fit(
        	x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid,y_valid)
        )
        #epochs: ìˆ˜í–‰ íšŸìˆ˜
        ```
        
        <img width="714" alt="image" src="https://github.com/Dororo99/nvidia_dli/assets/136609617/7bd70ca0-f794-4990-ba7f-cf20b26d9a4a">

        
- Clear the Memory
    
    ```python
    import IPython
    app = IPython.Application.instance()
    app.kernel.do_shutdown(True)
    ```
    

- ê°„ë‹¨í•œ ì‹¤ìŠµ
    
    ```python
    import numpy as np
    from numpy.polynomial.polynomial import polyfit
    import matplotlib.pyplot as plt
    
    m = 8  # -2 to start, change me please
    b = 5  # 40 to start, change me please
    
    # Sample data
    x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])
    y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])
    y_hat = x * m + b
    
    plt.plot(x, y, '.')
    plt.plot(x, y_hat, '-')
    plt.show()
    
    print("Loss:", np.sum((y - y_hat)**2)/len(x))
    ```
    
    <img width="726" alt="image" src="https://github.com/Dororo99/nvidia_dli/assets/136609617/daef66aa-b0ea-4e36-bba0-5a4cbcadf780">
